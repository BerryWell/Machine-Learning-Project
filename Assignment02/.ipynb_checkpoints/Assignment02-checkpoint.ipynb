{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 02\n",
    "\n",
    "```\n",
    "Build a binary classifier for human versus horse based on logistic regression using the dataset that consists of human and horse images\n",
    "```\n",
    "\n",
    "## Binary classification based on logistic regression\n",
    "\n",
    "$(x_i, y_i)$ denotes a pair of a training example and $i = 1, 2, \\cdots, n$\n",
    "\n",
    "$\\hat{y}_i = \\sigma(z_i)$ where $z_i = w^T x_i + b$ and $\\sigma(z) = \\frac{1}{1 + \\exp(-z)}$\n",
    "\n",
    "The loss function is defined by $\\mathcal{L} = \\frac{1}{n} \\sum_{i=1}^n f_i(w, b)$\n",
    "\n",
    "$f_i(w, b) = - y_i \\log \\hat{y}_i - (1 - y_i) \\log (1 - \\hat{y}_i) $\n",
    "\n",
    "## Dataset\n",
    "\n",
    "- The dataset consists of human images and horse images for the training and the validation\n",
    "- The classifier should be trained using the training set\n",
    "- The classifier should be tested using the validation set\n",
    "\n",
    "## Implementation\n",
    "\n",
    "- Write codes in python programming\n",
    "- Use ```jupyter notebook``` for the programming environment\n",
    "- You have to write your own implementation for the followings:\n",
    "    - compute the loss\n",
    "    - compute the accuracy\n",
    "    - compute the gradient of the model parameters with respect to the loss\n",
    "    - update the model parameters\n",
    "    - plot the results\n",
    "\n",
    "## Optimization\n",
    "\n",
    "- Apply the gradient descent algorithm with an appropriate learning rate\n",
    "- Apply the number of iterations that lead to the convergence of the algorith\n",
    "- Use the vectorization scheme in the computation of gradients and the update of the model parameters\n",
    "\n",
    "## git commit\n",
    "\n",
    "- Apply a number of ```git commit``` at intermediate development steps with their descriptive comments \n",
    "\n",
    "## Output\n",
    "\n",
    "- Plot the training loss at every iteration (x-axis: iteration, y-axis: loss)\n",
    "- Plot the validation loss at every iteration (x-axis: iteration, y-axis: loss)\n",
    "- Plot the training accuracy at every iteration (x-axis: iteration, y-axis: accuracy)\n",
    "- Plot the validation accuracy at every iteration (x-axis: iteration, y-axis: accuracy)\n",
    "- Present the table for the final accuracy and loss with training and validation datasets as below:\n",
    "\n",
    "| dataset    | loss       | accuracy   | \n",
    "|:----------:|:----------:|:----------:|\n",
    "| training   |            |            |\n",
    "| validation |            |            |\n",
    "\n",
    "## Submission\n",
    "\n",
    "- A PDF file exported from jupyter notebook for codes, results and comments [example: 20191234_02.pdf]\n",
    "- A PDF file exported from the github website for the history of git commit [example: 20191234_02_git.pdf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport torch\\nfrom torch.utils.data import Dataset, DataLoader\\nimport torchvision.transforms as transforms\\nimport torchvision\\nimport os\\n\\nNUM_EPOCH = 1\\n\\ntransform = transforms.Compose([#transforms.Resize((256,256)),  \\n                                transforms.Grayscale(),\\t\\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\\n                                transforms.ToTensor(),])\\n\\n\\n#train_data_path = 'relative path of training data set'\\ntrain_data_path = './horse-or-human/train'\\ntrainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\\n# change the valuse of batch_size, num_workers for your program\\n# if shuffle=True, the data reshuffled at every epoch \\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=3, shuffle=False, num_workers=1)  \\n\\n\\nvalidation_data_path = './horse-or-human/validation'\\nvalset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\\n# change the valuse of batch_size, num_workers for your program\\nvalloader = torch.utils.data.DataLoader(valset, batch_size=3, shuffle=False, num_workers=1)  \\n\\n\\nfor epoch in range(NUM_EPOCH):\\n    # load training images of the batch size for every iteration\\n    for i, data in enumerate(trainloader):\\n\\n        # inputs is the image\\n        # labels is the class of the image\\n        inputs, labels = data\\n\\n        # if you don't change the image size, it will be [batch_size, 1, 100, 100]\\n        print(inputs.shape)\\n\\n        # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\\n        print(labels)  \\n\\n\\n\\n\\n\\n    # load validation images of the batch size for every iteration\\n    for i, data in enumerate(valloader):\\n        \\n        # inputs is the image\\n        # labels is the class of the image\\n        inputs, labels = data\\n\\n        # if you don't change the image size, it will be [batch_size, 1, 100, 100]\\n        print(inputs.shape)\\n\\n        # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\\n        print(labels)    \\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "NUM_EPOCH = 1\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = './horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=3, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = './horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=3, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    # load training images of the batch size for every iteration\n",
    "    for i, data in enumerate(trainloader):\n",
    "\n",
    "        # inputs is the image\n",
    "        # labels is the class of the image\n",
    "        inputs, labels = data\n",
    "\n",
    "        # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "        print(inputs.shape)\n",
    "\n",
    "        # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "        print(labels)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # load validation images of the batch size for every iteration\n",
    "    for i, data in enumerate(valloader):\n",
    "        \n",
    "        # inputs is the image\n",
    "        # labels is the class of the image\n",
    "        inputs, labels = data\n",
    "\n",
    "        # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "        print(inputs.shape)\n",
    "\n",
    "        # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "        print(labels)    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "training_data_path = './horse-or-human/train'\n",
    "validation_data_path = './horse-or-human/validation'\n",
    "\n",
    "training_data_list_horses = glob(os.path.join(training_data_path, 'horses/*'))\n",
    "training_data_list_humans = glob(os.path.join(training_data_path, 'humans/*'))\n",
    "\n",
    "validation_data_list_horses = glob(os.path.join(validation_data_path, 'horses/*'))\n",
    "validation_data_list_humans = glob(os.path.join(validation_data_path, 'humans/*'))\n",
    "\n",
    "# 0 for horses\n",
    "# 1 for humans\n",
    "\n",
    "width = 100\n",
    "height = 100\n",
    "\n",
    "number_of_training_data_horses = len(training_data_list_horses)\n",
    "number_of_training_data_humans = len(training_data_list_humans)\n",
    "\n",
    "number_of_validation_data_horses = len(validation_data_list_horses)\n",
    "number_of_validation_data_humans = len(validation_data_list_humans)\n",
    "\n",
    "number_of_training_data = number_of_training_data_horses + number_of_training_data_humans\n",
    "number_of_validation_data = number_of_validation_data_horses + number_of_validation_data_humans\n",
    "\n",
    "training_data_horses = np.zeros((len(training_data_list_horses), width, height))\n",
    "training_data_humans = np.zeros((len(training_data_list_humans), width, height))\n",
    "\n",
    "validation_data_horses = np.zeros((len(validation_data_list_horses), width, height))\n",
    "validation_data_humans = np.zeros((len(validation_data_list_humans), width, height))\n",
    "\n",
    "# index x width x height\n",
    "for i, fname in enumerate(training_data_list_horses):\n",
    "    tmp = Image.open(fname)\n",
    "    training_data_horses[i,:,:] = np.array(tmp)\n",
    "\n",
    "for i, fname in enumerate(training_data_list_humans):\n",
    "    tmp = Image.open(fname)\n",
    "    training_data_humans[i,:,:] = np.array(tmp)\n",
    "\n",
    "for i, fname in enumerate(validation_data_list_horses):\n",
    "    tmp = Image.open(fname)\n",
    "    validation_data_horses[i,:,:] = np.array(tmp)\n",
    "    \n",
    "for i, fname in enumerate(validation_data_list_humans):\n",
    "    tmp = Image.open(fname)\n",
    "    validation_data_humans[i,:,:] = np.array(tmp)\n",
    "\n",
    "training_data = np.vstack((training_data_horses, training_data_humans))\n",
    "validation_data = np.vstack((validation_data_horses, validation_data_humans))\n",
    "\n",
    "training_data_label = np.ones((number_of_training_data))\n",
    "validation_data_label = np.ones((number_of_validation_data))\n",
    "for i in range(len(training_data_list_horses)):\n",
    "    training_data_label[i] = 0\n",
    "for i in range(len(validation_data_list_horses)):\n",
    "    validation_data_label[i] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to index x data\n",
    "training_data = training_data.reshape(number_of_training_data, width*height)\n",
    "validation_data = validation_data.reshape(number_of_validation_data, width*height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    result = 1/(1+np.exp(-x))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y, y_hat):\n",
    "    #if(y_hat <= 0):\n",
    "    #    print('y_hat <= 0!')\n",
    "    #    y_hat = 1e-7\n",
    "    #elif(y_hat >=1):\n",
    "    #    print('y_hat >= 1!')\n",
    "    #    y_hat = 1-1e07\n",
    "    result = -y*np.log(y_hat) - (1-y)*np.log(1-y_hat)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(f, x, h=1e-5):\n",
    "    result = (f(x+h)-f(x)) / h\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        # f(x+h) 계산\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(y):\n",
    "    if(y>=0.5):\n",
    "        return 1\n",
    "    elif(y<0.5):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$(x_i, y_i)$ denotes a pair of a training example and $i = 1, 2, \\cdots, n$\n",
    "\n",
    "$\\hat{y}_i = \\sigma(z_i)$ where $z_i = w^T x_i + b$ and $\\sigma(z) = \\frac{1}{1 + \\exp(-z)}$\n",
    "\n",
    "The loss function is defined by $\\mathcal{L} = \\frac{1}{n} \\sum_{i=1}^n f_i(w, b)$\n",
    "\n",
    "$f_i(w, b) = - y_i \\log \\hat{y}_i - (1 - y_i) \\log (1 - \\hat{y}_i) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compute the loss\n",
    "- compute the accuracy\n",
    "- compute the gradient of the model parameters with respect to the loss\n",
    "- update the model parameters\n",
    "- plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "- Plot the training loss at every iteration (x-axis: iteration, y-axis: loss)\n",
    "- Plot the validation loss at every iteration (x-axis: iteration, y-axis: loss)\n",
    "- Plot the training accuracy at every iteration (x-axis: iteration, y-axis: accuracy)\n",
    "- Plot the validation accuracy at every iteration (x-axis: iteration, y-axis: accuracy)\n",
    "- Present the table for the final accuracy and loss with training and validation datasets as below:\n",
    "\n",
    "| dataset    | loss       | accuracy   | \n",
    "|:----------:|:----------:|:----------:|\n",
    "| training   |            |            |\n",
    "| validation |            |            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_w(w, x=0, h=1e-5):\n",
    "    result = ((w+h) + (w-h)) / 2*h\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_b(b, x=0, h=1e-5):\n",
    "    result = ((b+h) - (b-h)) / 2*h\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [0]\n",
      "epoch [1]\n",
      "epoch [2]\n",
      "epoch [3]\n",
      "epoch [4]\n",
      "epoch [5]\n",
      "epoch [6]\n",
      "epoch [7]\n",
      "epoch [8]\n",
      "epoch [9]\n",
      "epoch [10]\n",
      "epoch [11]\n",
      "epoch [12]\n",
      "epoch [13]\n",
      "epoch [14]\n",
      "epoch [15]\n",
      "epoch [16]\n",
      "epoch [17]\n",
      "epoch [18]\n",
      "epoch [19]\n",
      "epoch [20]\n",
      "epoch [21]\n",
      "epoch [22]\n",
      "epoch [23]\n",
      "epoch [24]\n",
      "epoch [25]\n",
      "epoch [26]\n",
      "epoch [27]\n",
      "epoch [28]\n",
      "epoch [29]\n",
      "epoch [30]\n",
      "epoch [31]\n",
      "epoch [32]\n",
      "epoch [33]\n",
      "epoch [34]\n",
      "epoch [35]\n",
      "epoch [36]\n",
      "epoch [37]\n",
      "epoch [38]\n",
      "epoch [39]\n",
      "epoch [40]\n",
      "epoch [41]\n",
      "epoch [42]\n",
      "epoch [43]\n",
      "epoch [44]\n",
      "epoch [45]\n",
      "epoch [46]\n",
      "epoch [47]\n",
      "epoch [48]\n",
      "epoch [49]\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "EPOCH = 50\n",
    "lrate = 1e-2\n",
    "h = 1e-7\n",
    "\n",
    "w = np.zeros((width*height, 1))\n",
    "b = 0\n",
    "training_loss = []\n",
    "training_accuracy = []\n",
    "\n",
    "\n",
    "y = training_data_label\n",
    "y_hat = np.zeros((number_of_training_data, 1))\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    for j in range(number_of_training_data):\n",
    "        x = training_data[j,:]\n",
    "        y_hat[j,0] = sigmoid(np.dot(w.transpose(), x) + b)\n",
    "            \n",
    "                \n",
    "    # loss calculation\n",
    "    training_loss_value = np.sum(cross_entropy(y, y_hat))\n",
    "    training_loss.append(training_loss_value)\n",
    "        \n",
    "    y_hat_label = np.where(y_hat>=0.5, 1, 0)\n",
    "    \n",
    "    for k in range(number_of_training_data):\n",
    "        pass\n",
    "        \n",
    "    # accuracy calculation\n",
    "    #training_accuracy_value = \n",
    "    #training_accuracy.append(accuracy_value)\n",
    "    \n",
    "    # Update the parameter w, b by gradient descent\n",
    "    w = w - lrate * (((training_loss_value+h) - (training_loss_value-h)) / 2*h)\n",
    "    b = b - lrate * (((training_loss_value+h) - (training_loss_value-h)) / 2*h)\n",
    "\n",
    "    print('epoch [%d]' % i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(EPOCH), training_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[731082.4326048115,\n",
       " 731082.4326066509,\n",
       " 731082.4326084923,\n",
       " 731082.4326103331,\n",
       " 731082.4326121741,\n",
       " 731082.4326140151,\n",
       " 731082.4326158558,\n",
       " 731082.4326176961,\n",
       " 731082.4326195376,\n",
       " 731082.4326213783,\n",
       " 731082.4326232189,\n",
       " 731082.4326250599,\n",
       " 731082.4326269004,\n",
       " 731082.4326287418,\n",
       " 731082.4326305825,\n",
       " 731082.432632423,\n",
       " 731082.4326342636,\n",
       " 731082.4326361051,\n",
       " 731082.4326379454,\n",
       " 731082.4326397873,\n",
       " 731082.4326416278,\n",
       " 731082.4326434687,\n",
       " 731082.4326453093,\n",
       " 731082.43264715,\n",
       " 731082.4326489909,\n",
       " 731082.4326508315,\n",
       " 731082.4326526728,\n",
       " 731082.4326545133,\n",
       " 731082.4326563545,\n",
       " 731082.432658195,\n",
       " 731082.4326600367,\n",
       " 731082.4326618769,\n",
       " 731082.4326637182,\n",
       " 731082.4326655589,\n",
       " 731082.4326674,\n",
       " 731082.4326692406,\n",
       " 731082.4326710815,\n",
       " 731082.4326729224,\n",
       " 731082.4326747634,\n",
       " 731082.4326766033,\n",
       " 731082.4326784447,\n",
       " 731082.4326802855,\n",
       " 731082.4326821263,\n",
       " 731082.4326839678,\n",
       " 731082.432685808,\n",
       " 731082.4326876488,\n",
       " 731082.4326894899,\n",
       " 731082.432691331,\n",
       " 731082.4326931718,\n",
       " 731082.4326950124]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5],\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       ...,\n",
       "       [0.5],\n",
       "       [0.5],\n",
       "       [0.5]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n",
      "[0.5]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_hat)):\n",
    "    print(y_hat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (10270, 1027)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-164d6e1b5df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnumber_of_training_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (10270, 1027)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(EPOCH*number_of_training_data, training_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
